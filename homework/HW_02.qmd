---
title: "Homework 2"
format: html
---

__Due Date:__ 2022-10-16 at 8:30 AM PT
---


__Name:__ Adam Seri-Levi



For this assignment, you will practice downloadings, cleaning, and analyzing data from the [National Risk Index (NRI)](https://hazards.fema.gov/nri/) and the [CDC Social Vulnerability Index (SVI)](https://www.atsdr.cdc.gov/placeandhealth/svi/index.html).

## Preparation

1. Create a 'data' folder in the root directory of your repository.
1. Inside the 'data' folder, create a 'raw' folder.
1. Add and commit a '.gitignore' file to the root directory of this repository that excludes all contents of the 'data' folder.
1. Download the county-level NRI and SVI data for the entire United States. Place the data in the 'data/raw' folder.
1. In the repository README, provide a brief (1-2 sentence) description of each file in the 'data' folder and a link to the original source of the data.

## Task 1 - NRI Data Cleaning

__1. Import the NRI data. Ensure that the [FIPS code](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code) variable ('STCOFIPS') is correctly identified as a string / character variable. Otherwise, the leading zeros will be removed.__


```{python}

#importing packages
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

nri_data=r"C:\Users\aserilevi\code\PRGS-Intro-to-Machine-Learning\data\raw\National Risk Index (NRI) County Level Data\NRI_Table_Counties.csv"
nri_df=pd.read_csv(nri_data)
nri_df['STCOFIPS'] = nri_df['STCOFIPS'].astype(str)
stcofips_column = 'STCOFIPS'
```

__2. Subset the NRI data to include only the 5-digit state/county FIPS code and all colums ending with '\_AFREQ' and '\_RISKR'. Each of these columns represents a different hazard type.__

```{python}
#Assigning the stcofips column to a variable
stcofips_column = 'STCOFIPS'

# Filter columns that end with '_AFREQ' or '_RISKR'
filtered_nri = nri_df.filter(regex='(_AFREQ|_RISKR)$').columns

# Include the STCOFIPS column
filtered_nri = [stcofips_column] + list(filtered_nri)

# Subset the DataFrame with only columns of interest
subset_nri = nri_df[filtered_nri]

# Restrict to rows where STCOFIPS has exactly 5 digits
subset_nri = subset_nri[subset_nri[stcofips_column].astype(str).str.match(r'^\d{5}$')]
```
__3. Create a table / dataframe that, for each hazard type, shows the number of missing values in the '\_AFREQ' and '\_RISKR' columns.__
```{python}
# Creating a function that counts missing values for each column in a dataFrame
def count_missing(df):
    return df.isna().sum()
# using the function to count missing in our subsetted dataframe
count_missing_subset_nri=count_missing(subset_nri)
# dropping the STCOFIPS column
count_missing_subset_nri = count_missing_subset_nri.drop('STCOFIPS')
# converting to dataframe
count_missing_subset_nri= pd.DataFrame(count_missing_subset_nri)
print(count_missing_subset_nri)
```

__4. Show the cross-tabulation of the 'AVLN_AFREQ' and 'AVLN_RISKR' columns (including missing values). What do you observe?__
```{python}
#Creating a new column in the subset_nri dataframe that indicates where the value in AVLN_AFREQ is missing or observed
subset_nri['AVLN_AFREQ_MISSING'] = np.where(subset_nri['AVLN_AFREQ'].isna(),'Missing', 'Observed')

'''
##Checking that it worked
print(subset_nri[subset_nri['AVLN_AFREQ_MISSING'] == 'Observed'][['AVLN_AFREQ_MISSING', 'AVLN_AFREQ']])
'''
#cross tabulating, I noticed that there are no missing valuse except for wehn "AVLN_RISK" equals 'Not Applicable'. When it equals 'Not Applicable', "AVLN_RISK" is always missing, which makes sense since there is no risk associated when there isn't an applicable hazard

crosstab_df=pd.crosstab(
    subset_nri['AVLN_AFREQ_MISSING'],
    subset_nri['AVLN_RISKR'],
    dropna=False
)

print(crosstab_df)
```

__5. Assuming that a risk that is "not applicable" to a county has an annualized frequency of 0, impute the relevant missing values in the '\_AFREQ' columns with 0.__
```{python}
#Identifying which columns ends with _AFREQ and _RISKR and assigning each to a variable
afreq_columns = [col for col in subset_nri.columns if col.endswith('_AFREQ')]
riskr_columns = [col for col in subset_nri.columns if col.endswith('_RISKR')]

#Impute zero in '_AFREQ' columns where the corresponding '_RISKR'columns are 'Not Applicable'
for riskr_columns, afreq_columns in zip(riskr_columns, afreq_columns):
    subset_nri.loc[subset_nri[riskr_columns] == 'Not Applicable', afreq_columns] = 0

'''
##Can check that this works by running the previous python cell and then running this one again, there should be ZERO counts of "Missing" in the cross tabulation for 'Not Applicable'
print(crosstab_df)
'''

```


## Task 2 - SVI Data Cleaning

__1. Import the SVI data. Ensure that the FIPS code is correctly identified as a string / character variable. Otherwise, the leading zeros will be removed.__
__1. Subset the SVI data to include only the following columns:__
`ST, STATE, ST_ABBR, STCNTY, COUNTY, FIPS, LOCATION, AREA_SQMI, E_TOTPOP, EP_POV150, EP_UNEMP, EP_HBURD, EP_NOHSDP, EP_UNINSUR, EP_AGE65, EP_AGE17, EP_DISABL, EP_SNGPNT, EP_LIMENG, EP_MINRTY, EP_MUNIT, EP_MOBILE, EP_CROWD, EP_NOVEH, EP_GROUPQ, EP_NOINT, EP_AFAM, EP_HISP, EP_ASIAN, EP_AIAN, EP_NHPI, EP_TWOMORE, EP_OTHERRACE`
```{python}
svi_data= r"C:\Users\aserilevi\code\PRGS-Intro-to-Machine-Learning\data\raw\Social Vulnerability Index (SVI) County Level Data\SVI_2022_US_county.csv"
svi_df=pd.read_csv(svi_data)
svi_df['FIPS'] = svi_df['FIPS'].astype(str)

#identifying the columns I'm going to filter by
svi_columns = columns_to_select = [
    'ST', 'STATE', 'ST_ABBR', 'STCNTY', 'COUNTY', 'FIPS', 'LOCATION', 'AREA_SQMI',
    'E_TOTPOP', 'EP_POV150', 'EP_UNEMP', 'EP_HBURD', 'EP_NOHSDP', 'EP_UNINSUR', 'EP_AGE65', 
    'EP_AGE17', 'EP_DISABL', 'EP_SNGPNT', 'EP_LIMENG', 'EP_MINRTY', 'EP_MUNIT', 'EP_MOBILE', 
    'EP_CROWD', 'EP_NOVEH', 'EP_GROUPQ', 'EP_NOINT', 'EP_AFAM', 'EP_HISP', 'EP_ASIAN', 
    'EP_AIAN', 'EP_NHPI', 'EP_TWOMORE', 'EP_OTHERRACE'
]

#filtering the columns in the svi table 
filtered_svi=svi_df[svi_columns]
#print result
print(filtered_svi)
```

__2. Create a table / dataframe that shows the number of missing values in each column.
(Hint: if you wrote a function for Task 1, you can reuse it here.)__

```{python}
#using the function made in the previous task
svi_missing=count_missing(filtered_svi)
#turning it into a dataframe
svi_missing_df=pd.DataFrame(svi_missing)
#print result
print(svi_missing_df)
```

## Task 3 - Data Merging
__1. Identify any FIPS codes that are present in the NRI data but not in the SVI data and vice versa. Describe any discrepancies and possible causes? What to these discrepancies, if any, mean for interpreting results based on the merged dataset moving forward?__
```{python}
#The NRI dataset has 3 FIPS columns, one for state, one for county, and one for a combination of both, called state county (STCO). The SVI data has one column named FIPS and another column named STCNTY (State County) which can be interpreted in the same way as the STCOFIPS column from the NRI data and we should keep this in mind moving forward as we can use this as a key to merge our datasets
```

__2. Merge the NRI and SVI data on the FIPS code. Use an outer join to keep all counties in the final dataset.__
```{python}

##merging the subsetted and filtered dataframes on the FIPS and STCOFIPS keys
merged_nri_svi=pd.merge(subset_nri, filtered_svi, how='outer', left_on='STCOFIPS', right_on='FIPS')
#print result
print(merged_nri_svi)
```
__3. Create a table / dataframe that shows the number of missing values in each column of the merged dataset.__

```{python}
#using count_missing function to county how many missing values there are in merged dataframe
missing_merged=count_missing(merged_nri_svi)
missing_merged_df=pd.DataFrame(missing_merged)
#print result
print(missing_merged_df)
```

## Task 4 - Data Analysis

__1. For each numerical variable in the merged dataset, plot a histogram showing the distribution of values.
(Hint: write a function to make the histogram for a single variable, then use a loop or apply function to make the histograms for all numerical variables.)__

```{python}
def plot_histogram(data, bins=10, title='Histogram', xlabel='Values', ylabel='Frequency'):
    plt.figure(figsize=(8, 6))
    plt.hist(data, bins=bins, edgecolor='black')
    
    # Add title and axis labels
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    
    # Show the plot
    plt.show()
#checking to see if it worked
hist_test= plot_histogram(merged_nri_svi['EP_MINRTY'])
#assigning a variable that is only the numerical variables in the merged dataset
selecting_numerical_variables= merged_nri_svi.select_dtypes(include=['number'])
#applying the plot_Histogram function to all the numerical variables in the merged dataset
apply_hist=selecting_numerical_variables.apply(plot_histogram)

```
